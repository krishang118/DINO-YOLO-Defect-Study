{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Tuple, Optional\n",
    "from collections import defaultdict\n",
    "import json\n",
    "try:\n",
    "    import numpy as np\n",
    "except ImportError:\n",
    "    os.system(f\"{sys.executable} -m pip install -q numpy\")\n",
    "    import numpy as np\n",
    "try:\n",
    "    from tqdm.auto import tqdm\n",
    "except ImportError:\n",
    "    os.system(f\"{sys.executable} -m pip install -q tqdm\")\n",
    "    from tqdm.auto import tqdm\n",
    "try:\n",
    "    import cv2\n",
    "except ImportError:\n",
    "    os.system(f\"{sys.executable} -m pip install -q opencv-python\")\n",
    "    import cv2\n",
    "try:\n",
    "    from PIL import Image\n",
    "except ImportError:\n",
    "    os.system(f\"{sys.executable} -m pip install -q Pillow\")\n",
    "    from PIL import Image\n",
    "try:\n",
    "    import matplotlib\n",
    "    import matplotlib.pyplot as plt\n",
    "except ImportError:\n",
    "    os.system(f\"{sys.executable} -m pip install -q matplotlib\")\n",
    "    import matplotlib\n",
    "    import matplotlib.pyplot as plt\n",
    "HAS_PANDAS = False\n",
    "try:\n",
    "    import pandas as pd\n",
    "    HAS_PANDAS = True\n",
    "except (ImportError, ValueError):\n",
    "    print(f\"Pandas unavailable (optional)\")\n",
    "HAS_SEABORN = False\n",
    "if HAS_PANDAS:\n",
    "    try:\n",
    "        import seaborn as sns\n",
    "        sns.set_style(\"whitegrid\")\n",
    "        HAS_SEABORN = True\n",
    "    except (ImportError, ValueError):\n",
    "        print(f\"Seaborn unavailable (optional)\")\n",
    "if not HAS_SEABORN:\n",
    "    plt.style.use('default')\n",
    "    plt.rcParams['figure.facecolor'] = 'white'\n",
    "    plt.rcParams['axes.grid'] = True\n",
    "    plt.rcParams['grid.alpha'] = 0.3\n",
    "try:\n",
    "    import torch\n",
    "    import torch.nn as nn\n",
    "    import torch.nn.functional as F\n",
    "    from torchvision import transforms\n",
    "    from torch.utils.data import Dataset, DataLoader\n",
    "except ImportError:\n",
    "    os.system(f\"{sys.executable} -m pip install -q torch torchvision\")\n",
    "    import torch\n",
    "    import torch.nn as nn\n",
    "    import torch.nn.functional as F\n",
    "    from torchvision import transforms\n",
    "    from torch.utils.data import Dataset, DataLoader\n",
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "    device_name = \"Apple Silicon GPU (MPS)\"\n",
    "elif torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    device_name = f\"CUDA GPU ({torch.cuda.get_device_name(0)})\"\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    device_name = \"CPU\"\n",
    "print(f\"Compute device: {device_name}\")\n",
    "MVTEC_ROOT = Path(\"MVTecAD\")\n",
    "OUTPUT_DIR = Path(\"outputs\")\n",
    "MODELS_DIR = OUTPUT_DIR / \"models\"\n",
    "PSEUDO_LABELS_DIR = OUTPUT_DIR / \"pseudo_labels\"\n",
    "RESULTS_DIR = OUTPUT_DIR / \"results\"\n",
    "for dir_path in [OUTPUT_DIR, MODELS_DIR, PSEUDO_LABELS_DIR, RESULTS_DIR]:\n",
    "    dir_path.mkdir(parents=True, exist_ok=True)\n",
    "if not MVTEC_ROOT.exists():\n",
    "    raise FileNotFoundError(f\"MVTec AD dataset not found at {MVTEC_ROOT}\")\n",
    "else:\n",
    "    print(f\"Dataset found: {MVTEC_ROOT.absolute()}\")\n",
    "if not HAS_PANDAS:\n",
    "    print(\"\\nPandas/Seaborn unavailable\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_mvtec_dataset(root_path: Path) -> Dict:\n",
    "    categories = [d.name for d in root_path.iterdir()\n",
    "                  if d.is_dir() and not d.name.startswith('.')]\n",
    "    dataset_info = {}\n",
    "    for cat in sorted(categories):\n",
    "        cat_path = root_path / cat\n",
    "        train_good = cat_path / \"train\" / \"good\"\n",
    "        test_path = cat_path / \"test\"\n",
    "        info = {\n",
    "            'train_good': len(list(train_good.glob(\"*.png\"))) if train_good.exists() else 0,\n",
    "            'test_defects': {}}\n",
    "        if test_path.exists():\n",
    "            for defect_type in test_path.iterdir():\n",
    "                if defect_type.is_dir():\n",
    "                    info['test_defects'][defect_type.name] = len(list(defect_type.glob(\"*.png\")))\n",
    "        dataset_info[cat] = info\n",
    "    return dataset_info\n",
    "print(\"MVTecAD Dataset Analysis:\\n\")\n",
    "dataset_info = analyze_mvtec_dataset(MVTEC_ROOT)\n",
    "total_train = sum(info['train_good'] for info in dataset_info.values())\n",
    "total_test = sum(sum(info['test_defects'].values()) for info in dataset_info.values())\n",
    "print(f\"Total Categories: {len(dataset_info)}\")\n",
    "print(f\"Total Train Images: {total_train} (good samples)\")\n",
    "print(f\"Total Test Images: {total_test} (all types)\")\n",
    "print(\"\\nPer-Category Breakdown:\")\n",
    "print(f\"{'Category':<15} {'Train':<8} {'Test':<8} {'Defect Types'}\")\n",
    "for cat, info in sorted(dataset_info.items()):\n",
    "    n_defects = len(info['test_defects'])\n",
    "    n_test = sum(info['test_defects'].values())\n",
    "    print(f\"{cat:<15} {info['train_good']:<8} {n_test:<8} {n_defects}\")\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MVTecDataset(Dataset):    \n",
    "    def __init__(self, root: Path, category: str, split: str = 'train',\n",
    "                 transform=None, target_size: Tuple[int, int] = (224, 224)):\n",
    "        self.root = root\n",
    "        self.category = category\n",
    "        self.split = split\n",
    "        self.transform = transform\n",
    "        self.target_size = target_size\n",
    "        self.samples = []\n",
    "        self._load_samples()\n",
    "    def _load_samples(self):\n",
    "        cat_path = self.root / self.category / self.split\n",
    "        if self.split == 'train':\n",
    "            good_path = cat_path / \"good\"\n",
    "            if good_path.exists():\n",
    "                for img_path in sorted(good_path.glob(\"*.png\")):\n",
    "                    self.samples.append({\n",
    "                        'path': img_path,\n",
    "                        'label': 'good',\n",
    "                        'is_defect': False})\n",
    "        else:\n",
    "            for defect_type in sorted(cat_path.iterdir()):\n",
    "                if defect_type.is_dir():\n",
    "                    for img_path in sorted(defect_type.glob(\"*.png\")):\n",
    "                        self.samples.append({\n",
    "                            'path': img_path,\n",
    "                            'label': defect_type.name,\n",
    "                            'is_defect': defect_type.name != 'good'})\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "    def __getitem__(self, idx):\n",
    "        sample = self.samples[idx]\n",
    "        img = Image.open(sample['path']).convert('RGB')\n",
    "        img = img.resize(self.target_size, Image.BILINEAR)\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        return {\n",
    "            'image': img,\n",
    "            'label': sample['label'],\n",
    "            'is_defect': sample['is_defect'],\n",
    "            'path': str(sample['path'])}\n",
    "def get_transforms(size: int = 224):\n",
    "    return transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                             std=[0.229, 0.224, 0.225])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DINOFeatureExtractor:    \n",
    "    def __init__(self, model_name: str = 'dino_vits16', device='cpu'):\n",
    "        self.device = device\n",
    "        self.model_name = model_name\n",
    "        print(f\"\\nLoading DINO model: {model_name}\")        \n",
    "        try:\n",
    "            self.model = torch.hub.load('facebookresearch/dino:main', model_name,\n",
    "                                       force_reload=False, verbose=False)\n",
    "            self.model = self.model.to(device)\n",
    "            self.model.eval()\n",
    "            for param in self.model.parameters():\n",
    "                param.requires_grad = False\n",
    "            patch_size_attr = self.model.patch_embed.patch_size\n",
    "            if isinstance(patch_size_attr, (list, tuple)):\n",
    "                self.patch_size = patch_size_attr[0]\n",
    "            else:\n",
    "                self.patch_size = patch_size_attr\n",
    "            self.num_heads = self.model.blocks[0].attn.num_heads\n",
    "            print(f\"Model loaded successfully\")            \n",
    "        except Exception as e:\n",
    "            raise\n",
    "    def extract_attention_maps(self, img_tensor: torch.Tensor,\n",
    "                               layers: List[int] = [-1, -2, -3]) -> Dict[str, torch.Tensor]:\n",
    "        B, C, H, W = img_tensor.shape\n",
    "        with torch.no_grad():\n",
    "            attentions = []\n",
    "            def hook_fn(module, input, output):\n",
    "                if isinstance(output, tuple):\n",
    "                    attn_weights = output[1]\n",
    "                else:\n",
    "                    attn_weights = output\n",
    "                attentions.append(attn_weights)\n",
    "            hooks = []\n",
    "            for layer_idx in layers:\n",
    "                hook = self.model.blocks[layer_idx].attn.register_forward_hook(hook_fn)\n",
    "                hooks.append(hook)\n",
    "            features = self.model(img_tensor.to(self.device))\n",
    "            for hook in hooks:\n",
    "                hook.remove()\n",
    "        attention_maps = {}\n",
    "        h_patches = H // self.patch_size\n",
    "        w_patches = W // self.patch_size\n",
    "        for layer_idx, attn in zip(layers, attentions):\n",
    "            cls_attn = attn[:, :, 0, 1:]\n",
    "            cls_attn_avg = cls_attn.mean(dim=1)\n",
    "            attn_map = cls_attn_avg.reshape(B, h_patches, w_patches)\n",
    "            attention_maps[f'layer_{layer_idx}'] = attn_map\n",
    "        return {\n",
    "            'attention_maps': attention_maps,\n",
    "            'features': features,\n",
    "            'patch_grid': (h_patches, w_patches)}\n",
    "    def compute_anomaly_score(self, attention_maps: Dict[str, torch.Tensor],\n",
    "                             strategy: str = 'hierarchical') -> torch.Tensor:\n",
    "        maps = list(attention_maps.values())\n",
    "        if strategy == 'hierarchical':\n",
    "            weights = [0.5, 0.3, 0.2][:len(maps)]\n",
    "            score = sum(w * m for w, m in zip(weights, maps))\n",
    "        elif strategy == 'max':\n",
    "            score = torch.stack(maps).max(dim=0)[0]\n",
    "        else:\n",
    "            score = torch.stack(maps).mean(dim=0)\n",
    "        return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PseudoLabelGenerator:    \n",
    "    def __init__(self, dino_extractor: DINOFeatureExtractor):\n",
    "        self.dino = dino_extractor\n",
    "    def generate_pseudo_labels(self, img: np.ndarray,\n",
    "                               threshold_percentile: float = 95,\n",
    "                               min_box_size: int = 20,\n",
    "                               use_multiscale: bool = True) -> List[Dict]:\n",
    "        h, w = img.shape[:2]\n",
    "        transform = get_transforms()\n",
    "        img_tensor = transform(Image.fromarray(img)).unsqueeze(0)\n",
    "        pseudo_labels = []\n",
    "        scales = [1.0, 0.75, 1.25] if use_multiscale else [1.0]\n",
    "        for scale in scales:\n",
    "            if scale != 1.0:\n",
    "                new_h, new_w = int(h * scale), int(w * scale)\n",
    "                img_scaled = cv2.resize(img, (new_w, new_h))\n",
    "                img_tensor_scaled = transform(Image.fromarray(img_scaled)).unsqueeze(0)\n",
    "            else:\n",
    "                img_tensor_scaled = img_tensor\n",
    "                new_h, new_w = h, w\n",
    "            result = self.dino.extract_attention_maps(img_tensor_scaled)\n",
    "            anomaly_score = self.dino.compute_anomaly_score(\n",
    "                result['attention_maps'],\n",
    "                strategy='hierarchical')\n",
    "            score_np = anomaly_score[0].cpu().numpy()\n",
    "            threshold = np.percentile(score_np, threshold_percentile)\n",
    "            mask = (score_np > threshold).astype(np.uint8)\n",
    "            mask_resized = cv2.resize(mask, (new_w, new_h), interpolation=cv2.INTER_NEAREST)\n",
    "            num_labels, labels, stats, centroids = cv2.connectedComponentsWithStats(\n",
    "                mask_resized, connectivity=8)\n",
    "            for i in range(1, num_labels):\n",
    "                x, y, box_w, box_h, area = stats[i]\n",
    "                if box_w < min_box_size or box_h < min_box_size:\n",
    "                    continue\n",
    "                if scale != 1.0:\n",
    "                    x = int(x / scale)\n",
    "                    y = int(y / scale)\n",
    "                    box_w = int(box_w / scale)\n",
    "                    box_h = int(box_h / scale)\n",
    "                x_att = int((x / new_w) * score_np.shape[1])\n",
    "                y_att = int((y / new_h) * score_np.shape[0])\n",
    "                w_att = max(1, int((box_w / new_w) * score_np.shape[1]))\n",
    "                h_att = max(1, int((box_h / new_h) * score_np.shape[0]))\n",
    "                x_att = max(0, min(x_att, score_np.shape[1] - 1))\n",
    "                y_att = max(0, min(y_att, score_np.shape[0] - 1))\n",
    "                x_att_end = min(x_att + w_att, score_np.shape[1])\n",
    "                y_att_end = min(y_att + h_att, score_np.shape[0])\n",
    "                region_score = score_np[y_att:y_att_end, x_att:x_att_end].mean()\n",
    "                confidence = float(region_score)\n",
    "                pseudo_labels.append({\n",
    "                    'bbox': [int(x), int(y), int(box_w), int(box_h)],\n",
    "                    'confidence': float(confidence),\n",
    "                    'scale': float(scale)})\n",
    "        if len(pseudo_labels) > 0:\n",
    "            pseudo_labels = self._nms(pseudo_labels, iou_threshold=0.5)\n",
    "        return pseudo_labels\n",
    "    def _nms(self, boxes: List[Dict], iou_threshold: float = 0.5) -> List[Dict]:\n",
    "        if len(boxes) == 0:\n",
    "            return []\n",
    "        boxes = sorted(boxes, key=lambda x: x['confidence'], reverse=True)\n",
    "        keep = []\n",
    "        while len(boxes) > 0:\n",
    "            keep.append(boxes[0])\n",
    "            boxes = boxes[1:]\n",
    "            if len(boxes) == 0:\n",
    "                break\n",
    "            filtered = []\n",
    "            for box in boxes:\n",
    "                iou = self._compute_iou(keep[-1]['bbox'], box['bbox'])\n",
    "                if iou < iou_threshold:\n",
    "                    filtered.append(box)\n",
    "            boxes = filtered\n",
    "        return keep\n",
    "    def _compute_iou(self, box1: List[int], box2: List[int]) -> float:\n",
    "        x1, y1, w1, h1 = box1\n",
    "        x2, y2, w2, h2 = box2\n",
    "        xi1 = max(x1, x2)\n",
    "        yi1 = max(y1, y2)\n",
    "        xi2 = min(x1 + w1, x2 + w2)\n",
    "        yi2 = min(y1 + h1, y2 + h2)\n",
    "        inter_area = max(0, xi2 - xi1) * max(0, yi2 - yi1)\n",
    "        box1_area = w1 * h1\n",
    "        box2_area = w2 * h2\n",
    "        union_area = box1_area + box2_area - inter_area\n",
    "        return inter_area / union_area if union_area > 0 else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AIDefectReasoner:    \n",
    "    def __init__(self, category: str):\n",
    "        self.category = category\n",
    "        self.domain_priors = {\n",
    "            'critical_regions': [],\n",
    "            'texture_sensitivity': 0.5,\n",
    "            'object_sensitivity': 0.7}\n",
    "        self.known_defect_embeddings = []        \n",
    "        self.thresholds = {\n",
    "            'compactness': 0.6,\n",
    "            'edge_strength': 0.10,\n",
    "            'repetition': 0.3,\n",
    "            'severity_low': 0.3,\n",
    "            'severity_high': 0.6,\n",
    "            'trust_high': 0.4,     \n",
    "            'trust_low': 0.2}      \n",
    "    def analyze_defect_region(self,\n",
    "                             img: np.ndarray,\n",
    "                             bbox: List[int],\n",
    "                             attention_map: np.ndarray,\n",
    "                             layer_activations: Dict[str, np.ndarray]) -> Dict:\n",
    "        x, y, w, h = bbox\n",
    "        region = img[y:y+h, x:x+w]\n",
    "        reasoning_trace = []\n",
    "        defect_type, type_confidence = self._reason_about_type(\n",
    "            region, bbox, attention_map, layer_activations, reasoning_trace)\n",
    "        severity = self._reason_about_severity(\n",
    "            region, bbox, attention_map, defect_type, reasoning_trace)\n",
    "        confidence_vector = self._compute_confidence_vector(\n",
    "            region, bbox, attention_map, layer_activations, reasoning_trace)\n",
    "        trust_level = self._reason_about_trust(confidence_vector, reasoning_trace)\n",
    "        novelty = self._reason_about_novelty(region, reasoning_trace)\n",
    "        return {\n",
    "            'defect_type': defect_type,\n",
    "            'severity': float(severity),\n",
    "            'confidence_vector': confidence_vector,\n",
    "            'trust_level': trust_level,\n",
    "            'novelty': novelty,\n",
    "            'reasoning_trace': reasoning_trace,\n",
    "            'type_confidence': float(type_confidence)}\n",
    "    def _reason_about_type(self,\n",
    "                          region: np.ndarray,\n",
    "                          bbox: List[int],\n",
    "                          attention_map: np.ndarray,\n",
    "                          layer_activations: Dict[str, np.ndarray],\n",
    "                          trace: List[str]) -> Tuple[str, float]:\n",
    "        x, y, w, h = bbox\n",
    "        gray = cv2.cvtColor(region, cv2.COLOR_RGB2GRAY)\n",
    "        area = w * h\n",
    "        perimeter = 2 * (w + h)\n",
    "        compactness = (4 * np.pi * area) / (perimeter ** 2) if perimeter > 0 else 0\n",
    "        trace.append(f\"Compactness: {compactness:.3f}\")\n",
    "        edges = cv2.Canny(gray, 50, 150)\n",
    "        edge_strength = edges.sum() / (edges.shape[0] * edges.shape[1])\n",
    "        trace.append(f\"Edge strength: {edge_strength:.3f}\")\n",
    "        repetition_score = self._compute_repetition(gray)\n",
    "        trace.append(f\"Repetition: {repetition_score:.3f}\")\n",
    "        aspect_ratio = max(w, h) / (min(w, h) + 1e-6)\n",
    "        is_elongated = aspect_ratio > 2.5\n",
    "        trace.append(f\"Aspect ratio: {aspect_ratio:.2f}\")\n",
    "        early_layers = sum(layer_activations.get(f'layer_{i}', torch.tensor([0.0])).cpu().numpy().mean()\n",
    "                          for i in range(-11, -8))\n",
    "        late_layers = sum(layer_activations.get(f'layer_{i}', torch.tensor([0.0])).cpu().numpy().mean()\n",
    "                         for i in range(-3, 0))\n",
    "        layer_ratio = late_layers / (early_layers + 1e-6)\n",
    "        trace.append(f\"Layer ratio (late/early): {layer_ratio:.3f}\")\n",
    "        object_score = 0.0\n",
    "        texture_score = 0.0\n",
    "        if compactness > self.thresholds['compactness']:\n",
    "            object_score += 0.3\n",
    "            trace.append(\"→ Compact shape favors OBJECT\")\n",
    "        if edge_strength > self.thresholds['edge_strength']:\n",
    "            object_score += 0.3\n",
    "            trace.append(\"→ Strong edges favor OBJECT\")\n",
    "        if layer_ratio > 1.2:\n",
    "            object_score += 0.25\n",
    "            trace.append(\"→ Late layer dominance favors OBJECT\")\n",
    "        if repetition_score > self.thresholds['repetition']:\n",
    "            texture_score += 0.35\n",
    "            trace.append(\"→ High repetition favors TEXTURE\")\n",
    "        if is_elongated:\n",
    "            texture_score += 0.2\n",
    "            trace.append(\"→ Elongated shape favors TEXTURE\")\n",
    "        if layer_ratio < 0.8:\n",
    "            texture_score += 0.25\n",
    "            trace.append(\"→ Early layer dominance favors TEXTURE\")\n",
    "        if object_score > texture_score and object_score > 0.5:\n",
    "            defect_type = 'object'\n",
    "            confidence = object_score / (object_score + texture_score)\n",
    "        elif texture_score > 0.5:\n",
    "            defect_type = 'texture'\n",
    "            confidence = texture_score / (object_score + texture_score)\n",
    "        else:\n",
    "            defect_type = 'unknown'\n",
    "            confidence = 0.5\n",
    "        trace.append(f\"DECISION: {defect_type.upper()} (confidence: {confidence:.3f})\")\n",
    "        return defect_type, confidence\n",
    "    def _compute_repetition(self, gray: np.ndarray) -> float:\n",
    "        if gray.shape[0] < 10 or gray.shape[1] < 10:\n",
    "            return 0.0\n",
    "        f = np.fft.fft2(gray)\n",
    "        fshift = np.fft.fftshift(f)\n",
    "        magnitude = np.abs(fshift)\n",
    "        h, w = magnitude.shape\n",
    "        center_mask = np.zeros_like(magnitude)\n",
    "        center_mask[h//4:3*h//4, w//4:3*w//4] = 1\n",
    "        high_freq_energy = (magnitude * (1 - center_mask)).sum()\n",
    "        total_energy = magnitude.sum()\n",
    "        repetition = high_freq_energy / (total_energy + 1e-6)\n",
    "        return min(repetition * 2, 1.0)\n",
    "    def _reason_about_severity(self,\n",
    "                               region: np.ndarray,\n",
    "                               bbox: List[int],\n",
    "                               attention_map: np.ndarray,\n",
    "                               defect_type: str,\n",
    "                               trace: List[str]) -> float:\n",
    "        x, y, w, h = bbox\n",
    "        gray = cv2.cvtColor(region, cv2.COLOR_RGB2GRAY)\n",
    "        img_area = attention_map.shape[0] * attention_map.shape[1]\n",
    "        area_ratio = (w * h) / img_area\n",
    "        trace.append(f\"Area ratio: {area_ratio:.3f}\")\n",
    "        contrast_score = gray.std() / 128.0\n",
    "        trace.append(f\"Contrast: {contrast_score:.3f}\")\n",
    "        edges = cv2.Canny(gray, 50, 150)\n",
    "        boundary_strength = edges.sum() / (edges.shape[0] * edges.shape[1])\n",
    "        trace.append(f\"Boundary: {boundary_strength:.3f}\")\n",
    "        attention_strength = attention_map.mean()\n",
    "        trace.append(f\"Attention: {attention_strength:.3f}\")\n",
    "        if defect_type == 'object':\n",
    "            severity = (\n",
    "                0.4 * area_ratio * 10 +\n",
    "                0.3 * boundary_strength * 5 +\n",
    "                0.2 * contrast_score +\n",
    "                0.1 * attention_strength)\n",
    "        else:\n",
    "            severity = (\n",
    "                0.2 * area_ratio * 10 +\n",
    "                0.3 * contrast_score +\n",
    "                0.3 * attention_strength +\n",
    "                0.2 * boundary_strength * 5)\n",
    "        severity = np.clip(severity, 0, 1)\n",
    "        trace.append(f\"Severity: {severity:.3f}\")\n",
    "        return severity\n",
    "    def _compute_confidence_vector(self,\n",
    "                                   region: np.ndarray,\n",
    "                                   bbox: List[int],\n",
    "                                   attention_map: np.ndarray,\n",
    "                                   layer_activations: Dict[str, np.ndarray],\n",
    "                                   trace: List[str]) -> Dict[str, float]:\n",
    "        trace.append(\"\\n--- Confidence Vector ---\")\n",
    "        attention_entropy = -np.sum(\n",
    "            attention_map * np.log(attention_map + 1e-10)\n",
    "        ) / np.log(attention_map.size)\n",
    "        attention_confidence = 1.0 - attention_entropy\n",
    "        trace.append(f\"Attention conf: {attention_confidence:.3f}\")\n",
    "        gray = cv2.cvtColor(region, cv2.COLOR_RGB2GRAY)\n",
    "        edges = cv2.Canny(gray, 50, 150)\n",
    "        boundary_clarity = edges.sum() / (edges.shape[0] * edges.shape[1])\n",
    "        detection_confidence = min(boundary_clarity * 10, 1.0)\n",
    "        trace.append(f\"Detection conf: {detection_confidence:.3f}\")\n",
    "        layer_values = [act.cpu().numpy().mean() for act in layer_activations.values()]\n",
    "        if len(layer_values) > 1:\n",
    "            layer_std = np.std(layer_values)\n",
    "            stability_confidence = 1.0 / (1.0 + layer_std)\n",
    "        else:\n",
    "            stability_confidence = 0.5\n",
    "        trace.append(f\"Stability conf: {stability_confidence:.3f}\")\n",
    "        x, y, w, h = bbox\n",
    "        size_reasonable = 0.01 < (w * h) / (region.shape[0] * region.shape[1]) < 0.5\n",
    "        domain_consistency = 1.0 if size_reasonable else 0.5\n",
    "        trace.append(f\"Domain conf: {domain_consistency:.3f}\")\n",
    "        return {\n",
    "            'attention': float(attention_confidence),\n",
    "            'detection': float(detection_confidence),\n",
    "            'stability': float(stability_confidence),\n",
    "            'domain': float(domain_consistency)}\n",
    "    def _reason_about_trust(self,\n",
    "                           confidence_vector: Dict[str, float],\n",
    "                           trace: List[str]) -> str:\n",
    "        trace.append(\"\\n--- Trust Reasoning ---\")\n",
    "        avg_confidence = np.mean(list(confidence_vector.values()))\n",
    "        min_confidence = min(confidence_vector.values())\n",
    "        trace.append(f\"Avg conf: {avg_confidence:.3f}\")\n",
    "        trace.append(f\"Min conf: {min_confidence:.3f}\")\n",
    "        if avg_confidence > self.thresholds['trust_high'] and min_confidence > 0.6:\n",
    "            trust = 'high'\n",
    "            trace.append(\"TRUST: HIGH (all signals strong)\")\n",
    "        elif avg_confidence < self.thresholds['trust_low'] or min_confidence < 0.3:\n",
    "            trust = 'low'\n",
    "            trace.append(\"TRUST: LOW (weak signals)\")\n",
    "        else:\n",
    "            trust = 'medium'\n",
    "            trace.append(\"TRUST: MEDIUM (mixed signals)\")\n",
    "        return trust\n",
    "    def _reason_about_novelty(self, region: np.ndarray, trace: List[str]) -> str:\n",
    "        trace.append(\"\\n--- Novelty Assessment ---\")\n",
    "        gray = cv2.cvtColor(region, cv2.COLOR_RGB2GRAY)\n",
    "        hist, _ = np.histogram(gray.flatten(), bins=32, range=(0, 256))\n",
    "        hist = hist.astype(float) / (hist.sum() + 1e-6)\n",
    "        if len(self.known_defect_embeddings) == 0:\n",
    "            trace.append(\"No history - marking NOVEL\")\n",
    "            self.known_defect_embeddings.append(hist)\n",
    "            return 'novel'\n",
    "        similarities = [\n",
    "            np.sum(np.minimum(hist, known))\n",
    "            for known in self.known_defect_embeddings]\n",
    "        max_similarity = max(similarities)\n",
    "        trace.append(f\"Max similarity: {max_similarity:.3f}\")\n",
    "        if max_similarity > 0.8:\n",
    "            novelty = 'known'\n",
    "            trace.append(\"NOVELTY: KNOWN\")\n",
    "        elif max_similarity > 0.5:\n",
    "            novelty = 'variant'\n",
    "            trace.append(\"NOVELTY: VARIANT\")\n",
    "            self.known_defect_embeddings.append(hist)\n",
    "        else:\n",
    "            novelty = 'novel'\n",
    "            trace.append(\"NOVELTY: NOVEL\")\n",
    "            self.known_defect_embeddings.append(hist)\n",
    "        return novelty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class YOLODefectDetector:    \n",
    "    def __init__(self, model_size: str = 'n'):\n",
    "        try:\n",
    "            from ultralytics import YOLO\n",
    "            self.YOLO = YOLO\n",
    "            self.model = None\n",
    "            self.model_size = model_size\n",
    "            print(f\"YOLOv8 available\")\n",
    "        except ImportError:\n",
    "            print(\"Installing ultralytics (YOLOv8)...\")\n",
    "            os.system(f\"{sys.executable} -m pip install -q ultralytics\")\n",
    "            from ultralytics import YOLO\n",
    "            self.YOLO = YOLO\n",
    "            self.model = None\n",
    "            self.model_size = model_size\n",
    "            print(f\"YOLOv8 installed\")\n",
    "    def prepare_yolo_dataset(self, pseudo_labels_dict: Dict,\n",
    "                            output_dir: Path, category: str):\n",
    "        img_train_dir = output_dir / \"images\" / \"train\"\n",
    "        img_val_dir = output_dir / \"images\" / \"val\"\n",
    "        lbl_train_dir = output_dir / \"labels\" / \"train\"\n",
    "        lbl_val_dir = output_dir / \"labels\" / \"val\"\n",
    "        for d in [img_train_dir, img_val_dir, lbl_train_dir, lbl_val_dir]:\n",
    "            d.mkdir(parents=True, exist_ok=True)\n",
    "        items = list(pseudo_labels_dict.items())\n",
    "        split_idx = int(len(items) * 0.8)\n",
    "        train_items = items[:split_idx]\n",
    "        val_items = items[split_idx:]\n",
    "        def write_yolo_annotations(items, img_dir, lbl_dir):\n",
    "            for img_path, labels in items:\n",
    "                img = cv2.imread(img_path)\n",
    "                h, w = img.shape[:2]\n",
    "                img_name = Path(img_path).name\n",
    "                dst_img = img_dir / img_name\n",
    "                cv2.imwrite(str(dst_img), img)\n",
    "                lbl_name = img_name.replace('.png', '.txt')\n",
    "                dst_lbl = lbl_dir / lbl_name\n",
    "                with open(dst_lbl, 'w') as f:\n",
    "                    for lbl in labels:\n",
    "                        x, y, box_w, box_h = lbl['bbox']\n",
    "                        x_center = (x + box_w / 2) / w\n",
    "                        y_center = (y + box_h / 2) / h\n",
    "                        norm_w = box_w / w\n",
    "                        norm_h = box_h / h\n",
    "                        f.write(f\"0 {x_center:.6f} {y_center:.6f} {norm_w:.6f} {norm_h:.6f}\\n\")\n",
    "        write_yolo_annotations(train_items, img_train_dir, lbl_train_dir)\n",
    "        write_yolo_annotations(val_items, img_val_dir, lbl_val_dir)\n",
    "        data_yaml = output_dir / \"data.yaml\"\n",
    "        with open(data_yaml, 'w') as f:\n",
    "            f.write(f\"path: {output_dir.absolute()}\\n\")\n",
    "            f.write(f\"train: images/train\\n\")\n",
    "            f.write(f\"val: images/val\\n\")\n",
    "            f.write(f\"nc: 1\\n\")\n",
    "            f.write(f\"names: ['defect']\\n\")\n",
    "        print(f\"YOLO dataset: {len(train_items)} train, {len(val_items)} val\")\n",
    "        return data_yaml\n",
    "    def train(self, data_yaml: Path, epochs: int = 50, imgsz: int = 224):\n",
    "        print(f\"\\nTraining YOLOv8{self.model_size}...\")\n",
    "        self.model = self.YOLO(f'yolov8{self.model_size}.pt')\n",
    "        results = self.model.train(\n",
    "            data=str(data_yaml),\n",
    "            epochs=epochs,\n",
    "            imgsz=imgsz,\n",
    "            batch=16,\n",
    "            device='mps' if device.type == 'mps' else ('cuda' if device.type == 'cuda' else 'cpu'),\n",
    "            patience=10,\n",
    "            save=True,\n",
    "            project=str(MODELS_DIR),\n",
    "            name='yolo_defect_detector',\n",
    "            exist_ok=True,\n",
    "            verbose=False)\n",
    "        print(f\"Training completed\")\n",
    "        return results\n",
    "    def detect(self, img: np.ndarray, conf_threshold: float = 0.01) -> List[Dict]:\n",
    "        if self.model is None:\n",
    "            raise ValueError(\"Model not trained yet\")        \n",
    "        results = self.model(img, conf=conf_threshold, verbose=False)[0]\n",
    "        detections = []        \n",
    "        if len(results.boxes) == 0:\n",
    "            results = self.model(img, conf=0.001, verbose=False)[0]        \n",
    "        for box in results.boxes:\n",
    "            x1, y1, x2, y2 = box.xyxy[0].cpu().numpy()\n",
    "            conf = float(box.conf[0])\n",
    "            cls = int(box.cls[0])\n",
    "            detections.append({\n",
    "                'bbox': [int(x1), int(y1), int(x2-x1), int(y2-y1)],\n",
    "                'confidence': conf,\n",
    "                'class': cls})\n",
    "        return detections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClosedLoopRefinement:    \n",
    "    def __init__(self, dino_extractor: DINOFeatureExtractor,\n",
    "                 pseudo_label_gen: PseudoLabelGenerator):\n",
    "        self.dino = dino_extractor\n",
    "        self.pseudo_gen = pseudo_label_gen\n",
    "        self.threshold_percentile = 90\n",
    "        self.min_box_size = 10\n",
    "        self.refinement_history = []\n",
    "    def refine_from_detector_feedback(self,\n",
    "                                     img: np.ndarray,\n",
    "                                     yolo_detections: List[Dict],\n",
    "                                     ground_truth_label: str) -> Dict:\n",
    "        pseudo_labels = self.pseudo_gen.generate_pseudo_labels(\n",
    "            img,\n",
    "            threshold_percentile=self.threshold_percentile,\n",
    "            min_box_size=self.min_box_size)\n",
    "        n_pseudo = len(pseudo_labels)\n",
    "        n_yolo = len(yolo_detections)\n",
    "        if ground_truth_label != 'good':\n",
    "            if n_yolo > n_pseudo:\n",
    "                self.threshold_percentile = max(90, self.threshold_percentile - 1)\n",
    "            elif n_yolo < n_pseudo and n_yolo == 0:\n",
    "                self.threshold_percentile = min(99, self.threshold_percentile + 1)\n",
    "        else:\n",
    "            if n_yolo > 0:\n",
    "                self.min_box_size = min(50, self.min_box_size + 2)\n",
    "        self.refinement_history.append({\n",
    "            'threshold_percentile': self.threshold_percentile,\n",
    "            'min_box_size': self.min_box_size,\n",
    "            'n_pseudo': n_pseudo,\n",
    "            'n_yolo': n_yolo,\n",
    "            'ground_truth': ground_truth_label})\n",
    "        return {\n",
    "            'adjusted_params': {\n",
    "                'threshold_percentile': self.threshold_percentile,\n",
    "                'min_box_size': self.min_box_size\n",
    "            },\n",
    "            'agreement_stats': {\n",
    "                'n_pseudo_labels': n_pseudo,\n",
    "                'n_yolo_detections': n_yolo\n",
    "            }}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InspectionDecisionEngine:    \n",
    "    def __init__(self,\n",
    "                 accept_threshold: float = 0.4,  \n",
    "                 reject_threshold: float = 0.3):\n",
    "        self.accept_threshold = accept_threshold\n",
    "        self.reject_threshold = reject_threshold\n",
    "    def make_decision(self,\n",
    "                     detections: List[Dict],\n",
    "                     defect_analyses: List[Dict],\n",
    "                     category: str) -> Dict:\n",
    "        if len(detections) == 0:\n",
    "            return {\n",
    "                'decision': 'AUTO_ACCEPT',\n",
    "                'defect_present': False,\n",
    "                'defects': [],\n",
    "                'confidence': 1.0,\n",
    "                'recommended_action': 'Accept product for shipment',\n",
    "                'reasoning': 'No defects detected',\n",
    "                'reasoning_traces': []}\n",
    "        filtered_analyses = []\n",
    "        filtered_detections = []\n",
    "        for det, analysis in zip(detections, defect_analyses):\n",
    "            x, y, w, h = det['bbox']\n",
    "            box_area = w * h\n",
    "            if box_area < (1024 * 1024 * 0.8):\n",
    "                filtered_detections.append(det)\n",
    "                filtered_analyses.append(analysis)\n",
    "        if len(filtered_detections) > 50:\n",
    "            sorted_pairs = sorted(\n",
    "                zip(filtered_detections, filtered_analyses),\n",
    "                key=lambda x: x[0]['confidence'],\n",
    "                reverse=True)\n",
    "            filtered_detections = [p[0] for p in sorted_pairs[:20]]\n",
    "            filtered_analyses = [p[1] for p in sorted_pairs[:20]]\n",
    "        defect_details = []\n",
    "        max_severity = 0.0\n",
    "        avg_confidence = 0.0\n",
    "        has_novel = False\n",
    "        low_trust_count = 0\n",
    "        all_traces = []\n",
    "        for det, analysis in zip(detections, defect_analyses):\n",
    "            severity = analysis['severity']\n",
    "            conf_vector = analysis['confidence_vector']\n",
    "            overall_confidence = np.mean(list(conf_vector.values()))\n",
    "            if analysis['trust_level'] == 'low':\n",
    "                low_trust_count += 1\n",
    "            if analysis['novelty'] == 'novel':\n",
    "                has_novel = True\n",
    "            defect_details.append({\n",
    "                'bbox': det['bbox'],\n",
    "                'type': analysis['defect_type'],\n",
    "                'severity': severity,\n",
    "                'confidence': float(overall_confidence),\n",
    "                'confidence_vector': conf_vector,\n",
    "                'trust_level': analysis['trust_level'],\n",
    "                'novelty': analysis['novelty'],\n",
    "                'type_confidence': analysis['type_confidence']})\n",
    "            max_severity = max(max_severity, severity)\n",
    "            avg_confidence += overall_confidence\n",
    "            all_traces.extend(analysis['reasoning_trace'])\n",
    "        if len(filtered_detections) == 0:\n",
    "            return {\n",
    "                'decision': 'AUTO_ACCEPT',\n",
    "                'defect_present': False,\n",
    "                'defects': [],\n",
    "                'confidence': 1.0,\n",
    "                'recommended_action': 'Accept - no significant defects',\n",
    "                'reasoning': 'All detections filtered as noise',\n",
    "                'reasoning_traces': []}\n",
    "        avg_confidence /= len(detections)\n",
    "        reasoning_parts = []        \n",
    "        if has_novel:\n",
    "            decision = 'FLAG_NEW_DEFECT'\n",
    "            action = 'Flag for engineering - novel defect pattern'\n",
    "            reasoning_parts.append('Novel defect detected')\n",
    "        elif low_trust_count / len(detections) > 0.8:\n",
    "            decision = 'HUMAN_REVIEW'\n",
    "            action = 'Flag for human inspection - low confidence'\n",
    "            reasoning_parts.append(f'Low trust: {low_trust_count}/{len(detections)}')\n",
    "        elif max_severity > 0.5 and avg_confidence > self.reject_threshold: \n",
    "            decision = 'AUTO_REJECT'\n",
    "            action = 'Reject product - critical defect'\n",
    "            reasoning_parts.append(f'Severity: {max_severity:.2f}, Conf: {avg_confidence:.2f}')\n",
    "        elif max_severity < 0.3 and avg_confidence < 0.3: \n",
    "            decision = 'AUTO_ACCEPT'\n",
    "            action = 'Accept - minor defects within tolerance'\n",
    "            reasoning_parts.append(f'Low severity: {max_severity:.2f}')\n",
    "        else:\n",
    "            decision = 'HUMAN_REVIEW'\n",
    "            action = 'Flag for human inspection - uncertain'\n",
    "            reasoning_parts.append(f'Borderline: sev={max_severity:.2f}, conf={avg_confidence:.2f}')\n",
    "        return {\n",
    "            'decision': decision,\n",
    "            'defect_present': True,\n",
    "            'defects': defect_details,\n",
    "            'confidence': float(avg_confidence),\n",
    "            'recommended_action': action,\n",
    "            'reasoning': ' | '.join(reasoning_parts),\n",
    "            'reasoning_traces': all_traces}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_attention_maps(img: np.ndarray,\n",
    "                            attention_maps: Dict[str, torch.Tensor],\n",
    "                            save_path: Optional[Path] = None):\n",
    "    n_layers = len(attention_maps)\n",
    "    fig, axes = plt.subplots(1, n_layers + 1, figsize=(4 * (n_layers + 1), 4))\n",
    "    axes[0].imshow(img)\n",
    "    axes[0].set_title('Original')\n",
    "    axes[0].axis('off')\n",
    "    for idx, (layer_name, attn_map) in enumerate(attention_maps.items()):\n",
    "        attn_np = attn_map[0].cpu().numpy()\n",
    "        attn_resized = cv2.resize(attn_np, (img.shape[1], img.shape[0]))\n",
    "        axes[idx + 1].imshow(img)\n",
    "        axes[idx + 1].imshow(attn_resized, alpha=0.6, cmap='jet')\n",
    "        axes[idx + 1].set_title(layer_name)\n",
    "        axes[idx + 1].axis('off')\n",
    "    plt.tight_layout()\n",
    "    if save_path:\n",
    "        plt.savefig(save_path, dpi=150, bbox_inches='tight')\n",
    "        plt.close()\n",
    "    else:\n",
    "        plt.show()\n",
    "def visualize_detection_result(img: np.ndarray,\n",
    "                               detections: List[Dict],\n",
    "                               decision: Dict,\n",
    "                               save_path: Optional[Path] = None):\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(10, 10))\n",
    "    ax.imshow(img)\n",
    "    for det in decision['defects']:\n",
    "        x, y, w, h = det['bbox']\n",
    "        severity = det['severity']\n",
    "        if severity > 0.7:\n",
    "            color = 'red'\n",
    "        elif severity > 0.4:\n",
    "            color = 'orange'\n",
    "        else:\n",
    "            color = 'yellow'\n",
    "        rect = plt.Rectangle((x, y), w, h, linewidth=3,\n",
    "                            edgecolor=color, facecolor='none')\n",
    "        ax.add_patch(rect)\n",
    "        label = f\"{det['type']}: {det['confidence']:.2f}\"\n",
    "        ax.text(x, y - 5, label, color=color, fontsize=10,\n",
    "               bbox=dict(boxstyle='round', facecolor='black', alpha=0.7))\n",
    "    decision_color = {\n",
    "        'AUTO_ACCEPT': 'green',\n",
    "        'AUTO_REJECT': 'red',\n",
    "        'HUMAN_REVIEW': 'orange',\n",
    "        'FLAG_NEW_DEFECT': 'purple'\n",
    "    }[decision['decision']]\n",
    "    ax.text(0.5, 0.98, f\"DECISION: {decision['decision']}\",\n",
    "           transform=ax.transAxes, fontsize=14, weight='bold',\n",
    "           color='white', ha='center', va='top',\n",
    "           bbox=dict(boxstyle='round', facecolor=decision_color, alpha=0.8))\n",
    "    ax.text(0.5, 0.02, decision['recommended_action'],\n",
    "           transform=ax.transAxes, fontsize=10,\n",
    "           color='white', ha='center', va='bottom',\n",
    "           bbox=dict(boxstyle='round', facecolor='black', alpha=0.7))\n",
    "    ax.axis('off')\n",
    "    plt.tight_layout()\n",
    "    if save_path:\n",
    "        plt.savefig(save_path, dpi=150, bbox_inches='tight')\n",
    "        plt.close()\n",
    "    else:\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DefectDiscoveryPipeline:    \n",
    "    def __init__(self, category: str):\n",
    "        self.category = category\n",
    "        print(\"\\n\")\n",
    "        print(f\"Initializing Defect Discovery Pipeline: {category}\")\n",
    "        print(\"\\n\")\n",
    "        print(\"1. Loading DINO Vision Transformer...\")\n",
    "        self.dino = DINOFeatureExtractor(model_name='dino_vits16', device=device)\n",
    "        print(\"2. Initializing pseudo-label generator...\")\n",
    "        self.pseudo_gen = PseudoLabelGenerator(self.dino)\n",
    "        print(\"3. Setting up AI reasoner...\")\n",
    "        self.reasoner = AIDefectReasoner(category=category)\n",
    "        print(\"4. Preparing YOLO detector...\")\n",
    "        self.yolo = YOLODefectDetector(model_size='n')\n",
    "        print(\"5. Initializing closed-loop refinement...\")\n",
    "        self.refinement = ClosedLoopRefinement(self.dino, self.pseudo_gen)\n",
    "        print(\"6. Creating inspection decision engine...\")\n",
    "        self.decision_engine = InspectionDecisionEngine()\n",
    "        print(\"\\nPipeline initialized\\n\")    \n",
    "    def generate_training_data(self, n_samples: int = 100):\n",
    "        print(\"\\n\")\n",
    "        print(f\"Phase 1: Pseudo-Label Generation -\")\n",
    "        print(\"\\n\")\n",
    "        test_dataset = MVTecDataset(\n",
    "            MVTEC_ROOT,\n",
    "            self.category,\n",
    "            split='test',\n",
    "            transform=None,\n",
    "            target_size=(224, 224))\n",
    "        all_defect_samples = [s for s in test_dataset.samples if s['is_defect']]\n",
    "        all_good_samples = [s for s in test_dataset.samples if not s['is_defect']]\n",
    "        print(f\"Dataset: {len(all_defect_samples)} defects, {len(all_good_samples)} good\")\n",
    "        import random\n",
    "        random.seed(42)\n",
    "        random.shuffle(all_defect_samples)\n",
    "        random.shuffle(all_good_samples)\n",
    "        defect_split = int(len(all_defect_samples) * 0.7)\n",
    "        good_split = int(len(all_good_samples) * 0.7)\n",
    "        train_defects = all_defect_samples[:defect_split]\n",
    "        eval_defects = all_defect_samples[defect_split:]\n",
    "        eval_goods = all_good_samples[good_split:]\n",
    "        self.held_out_defects = eval_defects\n",
    "        self.held_out_goods = eval_goods\n",
    "        print(f\"Split: {len(train_defects)} train, {len(eval_defects)} held-out defects\")\n",
    "        if len(train_defects) > n_samples:\n",
    "            train_defects = train_defects[:n_samples]\n",
    "        print(f\"Generating pseudo-labels for {len(train_defects)} images...\")\n",
    "        pseudo_labels_dict = {}\n",
    "        for sample in tqdm(train_defects):\n",
    "            img = np.array(Image.open(sample['path']).convert('RGB'))\n",
    "            labels = self.pseudo_gen.generate_pseudo_labels(\n",
    "                img,\n",
    "                threshold_percentile=90,\n",
    "                min_box_size=20,\n",
    "                use_multiscale=True)\n",
    "            if len(labels) > 0:\n",
    "                pseudo_labels_dict[str(sample['path'])] = labels\n",
    "        print(f\"\\nGenerated pseudo-labels for {len(pseudo_labels_dict)} images\")\n",
    "        pseudo_label_file = PSEUDO_LABELS_DIR / f\"{self.category}_pseudo_labels.json\"\n",
    "        with open(pseudo_label_file, 'w') as f:\n",
    "            json.dump(pseudo_labels_dict, f, indent=2)\n",
    "        return pseudo_labels_dict\n",
    "    def train_detector(self, pseudo_labels_dict: Dict, epochs: int = 50):\n",
    "        print(\"\\n\")\n",
    "        print(f\"Phase 2: YOLO Detector Training -\")\n",
    "        print(\"\\n\")\n",
    "        yolo_data_dir = PSEUDO_LABELS_DIR / f\"{self.category}_yolo_data\"\n",
    "        data_yaml = self.yolo.prepare_yolo_dataset(\n",
    "            pseudo_labels_dict,\n",
    "            yolo_data_dir,\n",
    "            self.category)\n",
    "        results = self.yolo.train(data_yaml, epochs=epochs, imgsz=224)\n",
    "        possible_paths = [\n",
    "            MODELS_DIR / \"yolo_defect_detector\" / \"weights\" / \"best.pt\",\n",
    "            MODELS_DIR / \"yolo_defect_detector2\" / \"weights\" / \"best.pt\",\n",
    "            MODELS_DIR / \"yolo_defect_detector3\" / \"weights\" / \"best.pt\"]\n",
    "        best_weights = None\n",
    "        for path in possible_paths:\n",
    "            if path.exists():\n",
    "                best_weights = path\n",
    "                break\n",
    "        if best_weights:\n",
    "            print(f\"\\nLoading trained weights: {best_weights}\")\n",
    "            self.yolo.model = self.yolo.YOLO(str(best_weights))\n",
    "            print(f\"Model loaded successfully\\n\")\n",
    "        else:\n",
    "            print(f\"\\nCould not find best.pt\\n\")\n",
    "        return results\n",
    "    def run_inference(self, img_path: str, visualize: bool = True, debug: bool = False) -> Dict:\n",
    "        img = np.array(Image.open(img_path).convert('RGB'))        \n",
    "        if debug:\n",
    "            print(f\"\\nDEBUG - Processing: {Path(img_path).name}\")\n",
    "            print(f\"  Image shape: {img.shape}\")\n",
    "        detections = self.yolo.detect(img, conf_threshold=0.001)\n",
    "        if debug:\n",
    "            print(f\"  Detections (conf=0.001): {len(detections)}\")\n",
    "            if len(detections) > 0:\n",
    "                for i, det in enumerate(detections[:3]):\n",
    "                    print(f\"    Box {i}: conf={det['confidence']:.4f}, bbox={det['bbox']}\")\n",
    "        if len(detections) == 0 and debug:\n",
    "            raw_results = self.yolo.model(img, conf=0.0001, verbose=False)[0]\n",
    "            print(f\"  Raw YOLO boxes (conf=0.0001): {len(raw_results.boxes)}\")\n",
    "            if len(raw_results.boxes) > 0:\n",
    "                for i, box in enumerate(raw_results.boxes[:3]):\n",
    "                    print(f\"    Raw box {i}: conf={float(box.conf[0]):.6f}\")\n",
    "        transform = get_transforms()\n",
    "        img_tensor = transform(Image.fromarray(img)).unsqueeze(0)\n",
    "        dino_result = self.dino.extract_attention_maps(img_tensor)\n",
    "        attention_map = self.dino.compute_anomaly_score(\n",
    "            dino_result['attention_maps'],\n",
    "            strategy='hierarchical'\n",
    "        )[0].cpu().numpy()\n",
    "        attention_resized = cv2.resize(attention_map, (img.shape[1], img.shape[0]))\n",
    "        defect_analyses = []\n",
    "        for det in detections:\n",
    "            analysis = self.reasoner.analyze_defect_region(\n",
    "                img,\n",
    "                det['bbox'],\n",
    "                attention_resized,\n",
    "                dino_result['attention_maps'])\n",
    "            defect_analyses.append(analysis)\n",
    "        decision = self.decision_engine.make_decision(\n",
    "            detections, defect_analyses, self.category)\n",
    "        if visualize:\n",
    "            save_path = RESULTS_DIR / f\"{Path(img_path).stem}_result.png\"\n",
    "            visualize_detection_result(img, detections, decision, save_path)\n",
    "            if not debug:\n",
    "                print(f\"Saved: {save_path}\")\n",
    "        return decision\n",
    "    def evaluate_on_test_set(self, n_samples: int = 50):\n",
    "        print(\"\\n\")\n",
    "        print(f\"Phase 3: Test Set Evaluation -\")\n",
    "        print(\"\\n\")\n",
    "        if not hasattr(self, 'held_out_defects'):\n",
    "            print(\"WARNING: No held-out samples\\n\")\n",
    "            test_dataset = MVTecDataset(MVTEC_ROOT, self.category, split='test', transform=None)\n",
    "            test_samples = test_dataset.samples[:n_samples]\n",
    "        else:\n",
    "            held_out = self.held_out_defects + self.held_out_goods\n",
    "            import random\n",
    "            random.shuffle(held_out)\n",
    "            test_samples = held_out[:min(n_samples, len(held_out))]\n",
    "            print(f\"Using {len(test_samples)} held-out samples\")\n",
    "            print(f\"  {sum(1 for s in test_samples if s['is_defect'])} defects, {sum(1 for s in test_samples if not s['is_defect'])} good\\n\")\n",
    "        results = {\n",
    "            'correct_accept': 0,\n",
    "            'correct_reject': 0,\n",
    "            'false_accept': 0,\n",
    "            'false_reject': 0,\n",
    "            'human_review': 0,\n",
    "            'decisions': []}\n",
    "        print(f\"Evaluating on {len(test_samples)} images...\")\n",
    "        for sample in tqdm(test_samples):\n",
    "            decision = self.run_inference(str(sample['path']), visualize=False, debug=False)\n",
    "            is_defect_gt = sample['is_defect']\n",
    "            decision_type = decision['decision']\n",
    "            defect_detected = decision['defect_present']\n",
    "            if decision_type in ['HUMAN_REVIEW', 'FLAG_NEW_DEFECT']:\n",
    "                results['human_review'] += 1\n",
    "            elif defect_detected and is_defect_gt:\n",
    "                results['correct_reject'] += 1\n",
    "            elif not defect_detected and not is_defect_gt:\n",
    "                results['correct_accept'] += 1\n",
    "            elif defect_detected and not is_defect_gt:\n",
    "                results['false_reject'] += 1\n",
    "            else:\n",
    "                results['false_accept'] += 1\n",
    "            results['decisions'].append({\n",
    "                'path': str(sample['path']),\n",
    "                'ground_truth': sample['label'],\n",
    "                'is_defect_gt': is_defect_gt,\n",
    "                'decision': decision_type})\n",
    "        total = len(test_samples)\n",
    "        automated = total - results['human_review']\n",
    "        total_defects = sum(1 for s in test_samples if s['is_defect'])\n",
    "        automation_rate = automated / total if total > 0 else 0.0\n",
    "        if automated > 0:\n",
    "            auto_correct = results['correct_accept'] + results['correct_reject']\n",
    "            automated_accuracy = auto_correct / automated\n",
    "        else:\n",
    "            automated_accuracy = 0.0\n",
    "        overall_accuracy = (results['correct_accept'] + results['correct_reject']) / total if total > 0 else 0.0\n",
    "        false_accept_rate = results['false_accept'] / total_defects if total_defects > 0 else 0.0\n",
    "        print(\"\\n\")\n",
    "        print(f\"Evaluation Results:\")\n",
    "        print(f\"Total: {total} ({total_defects} defects, {total - total_defects} good)\")\n",
    "        print(f\"\")\n",
    "        print(f\"Automation: {automation_rate:.1%} ({automated}/{total})\")\n",
    "        print(f\"Automated Accuracy: {automated_accuracy:.1%} (of {automated} automated)\")\n",
    "        print(f\"Overall Accuracy: {overall_accuracy:.1%}\")\n",
    "        print(f\"\")\n",
    "        print(f\"Correct Accept: {results['correct_accept']}\")\n",
    "        print(f\"Correct Reject: {results['correct_reject']}\")\n",
    "        print(f\"False Accept: {results['false_accept']} \", end=\"\")\n",
    "        if false_accept_rate == 0:\n",
    "            print(\"SAFE\")\n",
    "        elif false_accept_rate < 0.2:\n",
    "            print(\"Risk\")\n",
    "        else:\n",
    "            print(\"HIGH RISK\")\n",
    "        print(f\"False Reject: {results['false_reject']}\")\n",
    "        print(f\"Human Review: {results['human_review']} ({results['human_review']/total:.1%})\")\n",
    "        print(f\"\")\n",
    "        print(f\"False Accept Rate: {false_accept_rate:.1%} \", end=\"\")\n",
    "        if false_accept_rate == 0:\n",
    "            print(\"(Safe)\")\n",
    "        elif false_accept_rate < 0.5:\n",
    "            print(\"(Moderate Risk)\")\n",
    "        else:\n",
    "            print(\"(High Risk)\")\n",
    "        print(\"\\n\")\n",
    "        results_file = RESULTS_DIR / f\"{self.category}_evaluation.json\"\n",
    "        serializable = {\n",
    "            'category': self.category,\n",
    "            'total': total,\n",
    "            'total_defects': total_defects,\n",
    "            'automation_rate': float(automation_rate),\n",
    "            'automated_accuracy': float(automated_accuracy),\n",
    "            'overall_accuracy': float(overall_accuracy),\n",
    "            'false_accept_rate': float(false_accept_rate),\n",
    "            'correct_accept': results['correct_accept'],\n",
    "            'correct_reject': results['correct_reject'],\n",
    "            'false_accept': results['false_accept'],\n",
    "            'false_reject': results['false_reject'],\n",
    "            'human_review': results['human_review']}\n",
    "        with open(results_file, 'w') as f:\n",
    "            json.dump(serializable, f, indent=2)\n",
    "        return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    CATEGORY = 'grid'  # Change this for each category\n",
    "    N_PSEUDO_LABEL_SAMPLES = 100\n",
    "    TRAINING_EPOCHS = 50\n",
    "    N_EVAL_SAMPLES = 30\n",
    "    print(f\"\\nConfiguration:\")\n",
    "    print(f\" Category: {CATEGORY}\")\n",
    "    print(f\" Pseudo-label samples: {N_PSEUDO_LABEL_SAMPLES}\")\n",
    "    print(f\" Training epochs: {TRAINING_EPOCHS}\")\n",
    "    print(f\" Evaluation samples: {N_EVAL_SAMPLES}\")    \n",
    "    pipeline = DefectDiscoveryPipeline(category=CATEGORY)\n",
    "    pseudo_labels = pipeline.generate_training_data(n_samples=N_PSEUDO_LABEL_SAMPLES)\n",
    "    if len(pseudo_labels) < 10:\n",
    "        print(\"\\nToo few pseudo-labels\")\n",
    "        return\n",
    "    training_results = pipeline.train_detector(pseudo_labels, epochs=TRAINING_EPOCHS)\n",
    "    eval_results = pipeline.evaluate_on_test_set(n_samples=N_EVAL_SAMPLES)\n",
    "    print(\"\\n\")\n",
    "    print(f\"Phase 4: Visualization Examples -\")\n",
    "    print(\"\\n\")    \n",
    "    if hasattr(pipeline, 'held_out_defects'):\n",
    "        viz_samples = (pipeline.held_out_defects[:3] + pipeline.held_out_goods[:2])\n",
    "    else:\n",
    "        test_dataset = MVTecDataset(MVTEC_ROOT, CATEGORY, split='test')\n",
    "        defect_samples = [s for s in test_dataset.samples if s['is_defect']][:3]\n",
    "        good_samples = [s for s in test_dataset.samples if not s['is_defect']][:2]\n",
    "        viz_samples = defect_samples + good_samples\n",
    "    print(\"Running inference on samples...\")\n",
    "    for sample in viz_samples:\n",
    "        decision = pipeline.run_inference(str(sample['path']), visualize=True, debug=True)\n",
    "        gt = \"DEFECT\" if sample['is_defect'] else \"GOOD\"\n",
    "        print(f\" └─ GT={gt}, Decision={decision['decision']}\\n\")\n",
    "    print(\"\\n\")\n",
    "    print(f\"Pipeline Completed.\")\n",
    "    print(f\"\\nOutputs:\")\n",
    "    print(f\" Models: {MODELS_DIR}\")\n",
    "    print(f\" Pseudo-labels: {PSEUDO_LABELS_DIR}\")\n",
    "    print(f\" Results: {RESULTS_DIR}\")\n",
    "    print(\"\\n\")\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
